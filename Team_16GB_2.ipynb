{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PostgreSQL 9.3.4, compiled by Visual C++ build 1600, 64-bit']\n"
     ]
    }
   ],
   "source": [
    "#Database class to handle all PostgreSQL database connectivity and queries\n",
    "\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "\n",
    "class Database(object):\n",
    "    \n",
    "    def __init__(self, debug=False):\n",
    "\n",
    "        try:\n",
    "           self.con = psycopg2.connect(database='MSA8010', user='postgres', password='password') \n",
    "           self.con.autocommit = True\n",
    "           self.cur = self.con.cursor(cursor_factory=psycopg2.extras.DictCursor)\n",
    "           \n",
    "           if debug:\n",
    "               self.cur.execute('SELECT version()')          \n",
    "               print self.cur.fetchone()\n",
    "    \n",
    "        except:\n",
    "            print \"Error: unable to connect to database\"\n",
    "            return False\n",
    "\n",
    "\n",
    "    def read(self, sql, params=None, returnAll=True):\n",
    "\n",
    "        try:\n",
    "            #execute a sql select statement and return one or all rows        \n",
    "            self.cur.execute(sql, params)\n",
    "            if (returnAll):\n",
    "                return self.cur.fetchall()\n",
    "            else:\n",
    "                return self.cur.fetchone()\n",
    "        except:\n",
    "            print \"Database error\"\n",
    "            return False\n",
    "           \n",
    "           \n",
    "    def execute(self, sql, params):\n",
    "        try:\n",
    "            #Execute a sql command (insert, update, delete)\n",
    "            self.cur.execute(sql, params)\n",
    "            return \n",
    "        \n",
    "        except:\n",
    "            print \"Database error\"\n",
    "            return False\n",
    "       \n",
    "               \n",
    "    def close(self):       \n",
    "        # disconnect from server\n",
    "        self.cur.close()\n",
    "        \n",
    "\n",
    "db=Database(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241148 unique IP + user agents were preloaded.\n",
      "0 files were processed\n"
     ]
    }
   ],
   "source": [
    "# This program reads and parses all of the log files in a directory\n",
    "# It stores unique visits to a database (unique IP address and user agent)\n",
    "# It also calculates hourly total page loads and saves the totals to a database table\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "\n",
    "#create second database cursor for updating the records \n",
    "import DatabaseClass\n",
    "\n",
    "#create database connection\n",
    "db=DatabaseClass.Database()\n",
    "\n",
    "try:\n",
    "    #create list to hold hourly counts of activity\n",
    "    hourCount=[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "    #Count only UNIQUE visitors\n",
    "    #create dictionary to hold processed unique visitors\n",
    "    IPs={}  \n",
    "    \n",
    "    #pre-load dictionary with IPs already processed\n",
    "    rows=db.read(\"select userip, useragent from logs\")\n",
    "    for row in rows:\n",
    "        uniqueVisitor = row[0] + row[1]\n",
    "        IPs[uniqueVisitor] = 1\n",
    "        \n",
    "    print len(IPs), \"unique IP + user agents were preloaded.\"\n",
    "    \n",
    "    \n",
    "\n",
    "    fileCount=0\n",
    "    sourcePath=\"c:\\\\temp\\\\MSA8010\\\\test\\\\\"\n",
    "    lst = os.listdir(sourcePath)\n",
    "    \n",
    "    #loop through all files in the directory\n",
    "    for sourceFile in lst:\n",
    "        print sourceFile\n",
    "        sourceFilePath=sourcePath+sourceFile\n",
    "        if os.path.isdir(sourceFilePath):       #skip subdirectories\n",
    "            continue\n",
    "      \n",
    "        print \"Processing\",sourceFile\n",
    "        f = open(sourceFilePath, 'r')           #open the file\n",
    "        fileCount += 1\n",
    "\n",
    "        #keep counts of lines processed        \n",
    "        count=0\n",
    "        skipped=0       #skip over duplicates\n",
    "        inserted=0      #number of inserts into the database\n",
    "\n",
    "        #initialize list of hours in a day to hold activity during that hour        \n",
    "        for hr in range(0,24):\n",
    "            hourCount[hr]=0\n",
    "            \n",
    "        while True:\n",
    "            line=f.readline()\n",
    "            if line =='':       #break on end of file\n",
    "                break\n",
    "            count += 1          #line count\n",
    "    \n",
    "            if count %10000 == 0:\n",
    "                print \"COUNT=\",count\n",
    "    \n",
    "            if line[0] == '#':  #skip comment lines\n",
    "                continue\n",
    "        \n",
    "            d=line.split()      #log file fields are space delimeted\n",
    "            \n",
    "            hour=int(d[1][0:2])     #record hourly activity count\n",
    "            hourCount[hour] += 1\n",
    "            \n",
    "            \n",
    "            #we want only unique vistors\n",
    "            #record entries from the same IP and same user address only once \n",
    "            #create unique key from user's IP address and user agent string\n",
    "            uniqueVisitor = d[8]+d[9]   \n",
    "            if uniqueVisitor in IPs:\n",
    "                #print IPs\n",
    "                #print d[8],\"exists. Skipping\"\n",
    "                skipped += 1\n",
    "                continue\n",
    "\n",
    "            #cur.execute(\"\"\"INSERT INTO logs (LogDate,LogTime,UserIP,UserAgent,SourceFile)\n",
    "            #            VALUES (%s,%s,%s,%s,%s)\"\"\", \\\n",
    "            #            (d[0],d[1],d[8],d[9],sourceFile))\n",
    "            \n",
    "            inserted += 1\n",
    "            IPs[uniqueVisitor] = \"1\"    \n",
    "\n",
    "        #determine day of week for this log file. Mon=0, Sun=6\n",
    "        year, month, day = (int(x) for x in d[0].split('-'))    \n",
    "        dow = datetime.date(year, month, day).weekday()\n",
    "        \n",
    "        #record hourly counts for this day\n",
    "        for hr in range(0, 24):\n",
    "            if hr < 10 :\n",
    "                hour = '0'+str(hr)\n",
    "            else:\n",
    "                hour = str(hr)                \n",
    "            db.execute(\"\"\"INSERT INTO activity VALUES (%s,%s,%s,%s)\"\"\", (d[0],dow,hour,hourCount[hr]))\n",
    "        \n",
    "        f.close()       #close file\n",
    "        \n",
    "        print \"Processed\", count, \"log enries\"\n",
    "        print skipped,\" duplicates were skipped\"\n",
    "        print inserted,\"entries were inserted into the database\"\n",
    "        \n",
    "    \n",
    "except IOError:\n",
    "    print 'Error accessing files'\n",
    "    sys.exit(1)\n",
    "\n",
    "finally:\n",
    "\n",
    "    db.close()\n",
    "    \n",
    "    print fileCount, \"files were processed\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131.96.210.58 Georgia\n",
      "66.249.79.84 California\n",
      "Done. 2 records updated\n"
     ]
    }
   ],
   "source": [
    "# This program scrapes IP address locations from a web site http://whatsmyip.com\n",
    "# It uses regular expressions to locate the state in the hmtl page that is returned\n",
    "# There is a limit of 50 before the host locks us out.\n",
    "\n",
    "import re\n",
    "import urllib2 \n",
    "\n",
    "\n",
    "#create second database cursor for updating the records \n",
    "import DatabaseClass\n",
    "\n",
    "#create database connection\n",
    "db=DatabaseClass.Database()\n",
    "\n",
    "class CrawlIP:\n",
    "\n",
    "    def getState(self, ip):\n",
    "        host=\"http://whatismyipaddress.com/ip/\"\n",
    "        \n",
    "        req = urllib2.Request(host+ip, headers={ 'User-Agent': 'Mozilla/5.0' })\n",
    "        html = urllib2.urlopen(req).read()\n",
    "\n",
    "        #print html\n",
    "        \n",
    "        #get string with any number of characters (using .*?) after State/region:</th></td>\n",
    "        # .* means any char string and ? means non-greedy (stop at first match)\n",
    "        match= re.search(\"State/Region:</th><td>.*?</td></tr>\",html)        \n",
    "        if match:\n",
    "            loc = match.group(0)\n",
    "            loc = re.sub('State/Region:</th><td>','',loc) \n",
    "            state = re.sub('</td></tr>','',loc)\n",
    "        else:\n",
    "            state = \"Not Found\"\n",
    "        return state\n",
    "\n",
    "\n",
    "demo=True\n",
    "\n",
    "ip=CrawlIP()\n",
    "\n",
    "if demo:\n",
    "    ip1=\"131.96.210.58\"\n",
    "    ip2=\"66.249.79.84\"\n",
    "            \n",
    "    print ip1, ip.getState(ip1)\n",
    "    print ip2, ip.getState(ip2)\n",
    "    count=2\n",
    "    \n",
    "else:    \n",
    "    rows=db.read(\"select pkey, userIP from logs where state is null limit 100\")\n",
    "    \n",
    "    count=0\n",
    "    for row in rows:\n",
    "        count += 1\n",
    "        state=ip.getState(row[1])\n",
    "        print count, row[0], row[1], state\n",
    "        db.execute(\"update logs set state=%s where pkey=%s\", (state, row[0]))    \n",
    "\n",
    "print \"Done.\", count, \"records updated\"\n",
    "db.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 records updated\n"
     ]
    }
   ],
   "source": [
    "# This program determines the state of the user's IP address from a databse of IPs\n",
    "# We used this database when web scraping the data from http://whatsmyip.com stopped working\n",
    "# because we sent too many requests\n",
    "\n",
    "#create second database cursor for updating the records \n",
    "import DatabaseClass\n",
    "\n",
    "#create database connection\n",
    "db=DatabaseClass.Database()\n",
    "\n",
    "#get a subset of records where the state has not yet been determined \n",
    "rows=db.read(\"select pkey, userIP from logs where state is null order by pkey desc limit 100000\")\n",
    "\n",
    "count=0\n",
    "for row in rows:\n",
    "    count += 1    \n",
    "    getState=db.read(\"select city from ip_addresses where %s >=startip and %s <=endip order by startip desc limit 1\",(row[1], row[1]), False)\n",
    "\n",
    "    if getState==None:    \n",
    "        state=\"unknown\"\n",
    "    else:\n",
    "        state=getState[0]\n",
    "      \n",
    "    print count, row[0],row[1],state\n",
    "    \n",
    "    db.execute(\"update logs set state=%s where pkey=%s\", (state, row[0]))    \n",
    "\n",
    "print count, \"records updated\"\n",
    "db.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. 0 records were processed. 0 could not be processed.\n"
     ]
    }
   ],
   "source": [
    "# This program uses regular expressions to determine the operating system and\n",
    "# browser type from the user agent string reported in the logs\n",
    "\n",
    "import re\n",
    "\n",
    "#create second database cursor for updating the records \n",
    "import DatabaseClass\n",
    "\n",
    "#create database connection\n",
    "db=DatabaseClass.Database()\n",
    "\n",
    "#get a subset of records where the state has not yet been determined \n",
    "rows=db.read(\"select pkey, useragent from logs where browsername is null\")\n",
    "\n",
    "count=0\n",
    "emptyCount=0\n",
    "\n",
    "for row in rows:\n",
    "    count += 1    \n",
    "    #print count, row[0], row[1]\n",
    "\n",
    "    os=''\n",
    "    browser=''\n",
    "    \n",
    "    pkey=row[0]\n",
    "    ua=row[1]\n",
    "    \n",
    "    match = re.search(\"MSIE.*?;\", ua)   #Internet Explorer    \n",
    "    if match:\n",
    "        ver = match.group(0)\n",
    "        ver = re.sub('MSIE.','', ver) \n",
    "        ver = re.sub(';','', ver)\n",
    "        browser = 'IE '+ver\n",
    "    else:\n",
    "        match = re.search(\"Trident.*?;\", ua)    #also Internet Explorer\n",
    "        if match:\n",
    "            ver = match.group(0)\n",
    "            ver = re.sub('Trident.','', ver) \n",
    "            ver = re.sub(';','', ver)\n",
    "            browser = 'IE '+ver\n",
    "        \n",
    "        else:            \n",
    "            match = re.search(\"Firefox\",ua)      \n",
    "            if match:\n",
    "                browser = 'Firefox'\n",
    "            else:\n",
    "                match = re.search(\"Chrome\",ua)      \n",
    "                if match:\n",
    "                    browser='Chrome'\n",
    "                else:\n",
    "                    match = re.search(\"Safari\",ua)      \n",
    "                    if match:\n",
    "                        browser='Safari'\n",
    "                    else:\n",
    "                        browser='other'\n",
    "                    \n",
    "                \n",
    "            \n",
    "    #look for Windows - string may end with either ; or )\n",
    "    match = re.search(\"Windows.NT.*?[;)]\", ua)  \n",
    "    if match:\n",
    "        #print match.group(0)\n",
    "        \n",
    "        #Determine Windows version\n",
    "        ver = match.group(0)\n",
    "        ver = re.sub('Windows.','', ver) \n",
    "        ver = re.sub('[;)]','', ver)\n",
    "        \n",
    "        os='Windows '\n",
    "        if ver == 'NT+6.1': \n",
    "            os += '7'\n",
    "        elif ver == 'NT+6.2' or ver == 'NT+6.3':\n",
    "            os += '8'\n",
    "        elif ver == 'NT+6.0':\n",
    "            os += 'Vista'\n",
    "        elif ver == 'NT+10.0':\n",
    "            os += '10'\n",
    "        elif ver == 'NT+5.1' or ver == 'XP':\n",
    "            os += 'XP'\n",
    "        elif ver.startswith('Phone'):\n",
    "            os += 'Phone'\n",
    "    \n",
    "    else:\n",
    "        match = re.search(\"Android\", ua)  \n",
    "        if match:\n",
    "            os='Android'\n",
    "            \n",
    "        else:\n",
    "            match1 = re.search(\"iPhone\", ua)\n",
    "            match2 = re.search(\"iPad\", ua)\n",
    "\n",
    "            #Darwin is also used for iOS and Mac desktops    \n",
    "            darwin = re.search(\"Darwin\", ua)\n",
    "            if darwin:\n",
    "                browser='Safari'\n",
    "            mobileSafari =re.search(\"MobileSafari\", ua)\n",
    "            if mobileSafari:\n",
    "                browser='Safari'\n",
    "                \n",
    "            if match1 or match2 or (darwin and mobileSafari):\n",
    "                os='iOS'\n",
    "                if browser=='':\n",
    "                    browser = 'Safari'\n",
    "            else:\n",
    "                match = re.search(\"Macintosh\", ua)\n",
    "                if match or (darwin and not mobileSafari):\n",
    "                    os = 'Mac Desktop'\n",
    "                else:\n",
    "                    os = 'other'\n",
    "                \n",
    "    #print ua\n",
    "    if browser=='' or os=='':\n",
    "        emptyCount += 1\n",
    "        print emptyCount, pkey, \"b=\",browser, \"os=\",os, ua   \n",
    "    \n",
    "    db.execute(\"update logs set browsername=%s, browseros=%s where pkey=%s\", (browser, os, pkey))    \n",
    "            \n",
    "print \"Done.\", count, \"records were processed.\", emptyCount, \"could not be processed.\"  \n",
    "db.close()\n",
    "              \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PostgreSQL 9.3.4, compiled by Visual C++ build 1600, 64-bit']\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Axes' object has no attribute 'rowNum'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-1d06a89d61b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreateSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\tools\\plotting.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, kind, ax, figsize, use_index, title, grid, legend, style, logx, logy, loglog, xticks, yticks, xlim, ylim, rot, fontsize, colormap, table, yerr, xerr, label, secondary_y, **kwds)\u001b[0m\n\u001b[0;32m   3491\u001b[0m                            \u001b[0mcolormap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolormap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myerr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0myerr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3492\u001b[0m                            \u001b[0mxerr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxerr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msecondary_y\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msecondary_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3493\u001b[1;33m                            **kwds)\n\u001b[0m\u001b[0;32m   3494\u001b[0m     \u001b[0m__call__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplot_series\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3495\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\tools\\plotting.pyc\u001b[0m in \u001b[0;36mplot_series\u001b[1;34m(data, kind, ax, figsize, use_index, title, grid, legend, style, logx, logy, loglog, xticks, yticks, xlim, ylim, rot, fontsize, colormap, table, yerr, xerr, label, secondary_y, **kwds)\u001b[0m\n\u001b[0;32m   2581\u001b[0m                  \u001b[0myerr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0myerr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxerr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxerr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2582\u001b[0m                  \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msecondary_y\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msecondary_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2583\u001b[1;33m                  **kwds)\n\u001b[0m\u001b[0;32m   2584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\tools\\plotting.pyc\u001b[0m in \u001b[0;36m_plot\u001b[1;34m(data, x, y, subplots, ax, kind, **kwds)\u001b[0m\n\u001b[0;32m   2378\u001b[0m         \u001b[0mplot_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubplots\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2379\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2380\u001b[1;33m     \u001b[0mplot_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2381\u001b[0m     \u001b[0mplot_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2382\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mplot_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\tools\\plotting.pyc\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    990\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_post_plot_logic_common\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    991\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_post_plot_logic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 992\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_adorn_subplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    993\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    994\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_args_adjust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\tools\\plotting.pyc\u001b[0m in \u001b[0;36m_adorn_subplots\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1141\u001b[0m                                 \u001b[0mnaxes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnrows\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mncols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m                                 \u001b[0mncols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mncols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msharex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msharex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1143\u001b[1;33m                                 sharey=self.sharey)\n\u001b[0m\u001b[0;32m   1144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1145\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0max\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\tools\\plotting.pyc\u001b[0m in \u001b[0;36m_handle_shared_axes\u001b[1;34m(axarr, nplots, naxes, nrows, ncols, sharex, sharey)\u001b[0m\n\u001b[0;32m   3378\u001b[0m                 \u001b[0mlayout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mncols\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3379\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0max\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxarr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3380\u001b[1;33m                     \u001b[0mlayout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrowNum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolNum\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_visible\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3381\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3382\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0max\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxarr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Axes' object has no attribute 'rowNum'"
     ]
    }
   ],
   "source": [
    "#This program performs the regression calculations on trends and creates the plots\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy.stats\n",
    "\n",
    "#create second database cursor for updating the records \n",
    "import DatabaseClass\n",
    "\n",
    "#create database connection\n",
    "db=DatabaseClass.Database(True)\n",
    "\n",
    "def createSeries(resultSet):\n",
    "    #create dictionary to hold the data pairs {date:hits} in a database result set\n",
    "    d={}\n",
    "    for row in resultSet:\n",
    "        d[row[0]] = row[1]\n",
    "    return pd.Series(d)\n",
    "    \n",
    "#create time series plot of unique user visits per day\n",
    "#get a subset of records where the state has not yet been determined \n",
    "rows=db.read(\"select logdate, sum(hits) as hits from activity group by logdate order by logdate\")\n",
    "\n",
    "s=createSeries(rows)\n",
    "s.plot()\n",
    "print s.describe()\n",
    "\n",
    "\n",
    "\n",
    "#day of week analysis unsing dataFrame JOIN\n",
    "rows=db.read(\"select dayofweek,sum(hits) from activity group by dayofweek\")\n",
    "dow=createSeries(rows)\n",
    "dowDF=pd.DataFrame(dow, columns=[\"Unique_Visitors\"])\n",
    "\n",
    "#create labels for day of week values and join the data frames\n",
    "days=['Mon','Tues','Wed','Thurs','Fri','Sat','Sun']\n",
    "daysDF=pd.DataFrame(days, columns=[\"Day\"])\n",
    "\n",
    "uniqueVisitorDays = dowDF.join(daysDF)  #JOIN two data frames\n",
    "uniqueVisitorDays=uniqueVisitorDays.sort_values(\"Unique_Visitors\", ascending=0)\n",
    "print\n",
    "print uniqueVisitorDays\n",
    "\n",
    "#create labels\n",
    "labels=[]\n",
    "fractions=[]\n",
    "for i in range(7):\n",
    "    j=i+1\n",
    "    labels.append(uniqueVisitorDays[i:j].Day.item())\n",
    "\n",
    "#generate pie chart\n",
    "uniqueVisitorDays.plot(kind=\"pie\", autopct='%.2f%%', subplots=True, labels=labels, \\\n",
    "        colors=('g','r','b','m','c','y','w'))\n",
    "\n",
    "\n",
    "#Mobile user analysis\n",
    "\n",
    "#create time series plot of unique visitors per browser type per month\n",
    "dfData={}\n",
    "\n",
    "rows=db.read(\"select date_part('week',logdate) as week, count(browseros) from logs where browseros='Android' group by date_part('week',logdate),browseros order by date_part('week',logdate)\")\n",
    "dfData['Android'] = createSeries(rows)\n",
    "\n",
    "rows=db.read(\"select date_part('week',logdate) as week, count(browseros) from logs where browseros='iOS' group by date_part('week',logdate),browseros order by date_part('week',logdate)\")\n",
    "dfData['iOS'] = createSeries(rows)\n",
    "\n",
    "rows=db.read(\"select date_part('week',logdate) as week, count(browseros) from logs where browseros='Windows Phone' group by date_part('week',logdate),browseros order by date_part('week',logdate)\")\n",
    "dfData['Windows_Phone'] = createSeries(rows)\n",
    "\n",
    "rows=db.read(\"select date_part('week',logdate) as week, count(browseros) from logs where browseros in ('iOS','Android','Windows Phone') group by date_part('week',logdate) order by date_part('week',logdate)\")\n",
    "allMobile=rows      #save data for linear regression\n",
    "\n",
    "rows=db.read(\"select date_part('week',logdate) as week, count(browseros) from logs group by date_part('week',logdate) order by date_part('week',logdate)\")\n",
    "dfData['All_Visitors'] = createSeries(rows)\n",
    "allTraffic=rows     #save data for linear regression\n",
    "\n",
    "#sum all mobile traffic counts\n",
    "dfData['Mobile_Total'] =dfData['Android']+dfData['iOS']+dfData['Windows_Phone']\n",
    "\n",
    "df=pd.DataFrame(dfData)\n",
    "df=df.fillna(value=0)       #replace missing data with 0\n",
    "df.plot()\n",
    "\n",
    "print df.describe()\n",
    "\n",
    "\n",
    "#linear regession to find best fit line for all visitors\n",
    "y=[allTraffic[i][1] for i in range(len(allTraffic))]\n",
    "x=[allTraffic[i][0] for i in range(len(allTraffic))]\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(x,y)\n",
    "print\n",
    "print \"All Visitors\"\n",
    "print \"slope=\", slope\n",
    "print \"intercept=\", intercept\n",
    "print \"R-squared=\", r_value**2, \"standard error=\",std_err\n",
    "\n",
    "x=np.array(x)\n",
    "y=np.array(y)\n",
    "regressionLine=slope*x + intercept\n",
    "df['All_Regression']=regressionLine\n",
    "\n",
    "#linear regession to find best fit line for mobile users\n",
    "y=[allMobile[i][1] for i in range(len(allMobile))]\n",
    "x=[allMobile[i][0] for i in range(len(allMobile))]\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(x,y)\n",
    "print\n",
    "print \"All Mobile\"\n",
    "print \"slope=\", slope\n",
    "print \"intercept=\", intercept\n",
    "print \"R-squared=\", r_value**2, \"standard error=\",std_err\n",
    "\n",
    "x=np.array(x)\n",
    "y=np.array(y)\n",
    "regressionLine=slope*x + intercept\n",
    "df['Mobile_Regression']=regressionLine\n",
    "\n",
    "df.plot(); \n",
    "\n",
    "\n",
    "#Analysis of IE6 browsers and Windows XP users\n",
    "#create time series plot of unique visitors per browser type per month\n",
    "xp={}\n",
    "\n",
    "rows=db.read(\"select date_part('week',logdate) as week, count(browseros) from logs where browsername like 'IE 6%' or (browseros='Windows XP' and browsername like 'IE%') group by date_part('week',logdate) order by date_part('week',logdate)\")\n",
    "xpTraffic=rows      #save data for linear regression\n",
    "xp['XP'] = createSeries(rows)\n",
    "xp=pd.DataFrame(xp)\n",
    "xp=xp.fillna(value=0)       #replace missing data with 0\n",
    "\n",
    "#linear regession to find best fit line for all visitors\n",
    "y=[xpTraffic[i][1] for i in range(len(xpTraffic))]\n",
    "x=[xpTraffic[i][0] for i in range(len(xpTraffic))]\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(x,y)\n",
    "print\n",
    "print \"XP Browsers\"\n",
    "print \"slope=\", slope\n",
    "print \"intercept=\", intercept\n",
    "print \"R-squared=\", r_value**2, \"standard error=\",std_err\n",
    "\n",
    "x=np.array(x)\n",
    "y=np.array(y)\n",
    "regressionLine=slope*x + intercept\n",
    "xp['Regression']=regressionLine\n",
    "\n",
    "xp.plot()\n",
    "\n",
    "\n",
    "#Create U.S. map of user activity from IP address locations\n",
    "#matplotlib inline\n",
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib as mpl\n",
    "\n",
    "#state map of users\n",
    "states_abbrev = {\n",
    "        'AK': 'Alaska',\n",
    "        'AL': 'Alabama',\n",
    "        'AR': 'Arkansas',\n",
    "        'AZ': 'Arizona',\n",
    "        'CA': 'California',\n",
    "        'CO': 'Colorado',\n",
    "        'CT': 'Connecticut',\n",
    "        'DE': 'Delaware',\n",
    "        'FL': 'Florida',\n",
    "        'GA': 'Georgia',\n",
    "        'HI': 'Hawaii',\n",
    "        'IA': 'Iowa',\n",
    "        'ID': 'Idaho',\n",
    "        'IL': 'Illinois',\n",
    "        'IN': 'Indiana',\n",
    "        'KS': 'Kansas',\n",
    "        'KY': 'Kentucky',\n",
    "        'LA': 'Louisiana',\n",
    "        'MA': 'Massachusetts',\n",
    "        'MD': 'Maryland',\n",
    "        'ME': 'Maine',\n",
    "        'MI': 'Michigan',\n",
    "        'MN': 'Minnesota',\n",
    "        'MO': 'Missouri',\n",
    "        'MS': 'Mississippi',\n",
    "        'MT': 'Montana',\n",
    "        'NC': 'North Carolina',\n",
    "        'ND': 'North Dakota',\n",
    "        'NE': 'Nebraska',\n",
    "        'NH': 'New Hampshire',\n",
    "        'NJ': 'New Jersey',\n",
    "        'NM': 'New Mexico',\n",
    "        'NV': 'Nevada',\n",
    "        'NY': 'New York',\n",
    "        'OH': 'Ohio',\n",
    "        'OK': 'Oklahoma',\n",
    "        'OR': 'Oregon',\n",
    "        'PA': 'Pennsylvania',\n",
    "        'RI': 'Rhode Island',\n",
    "        'SC': 'South Carolina',\n",
    "        'SD': 'South Dakota',\n",
    "        'TN': 'Tennessee',\n",
    "        'TX': 'Texas',\n",
    "        'UT': 'Utah',\n",
    "        'VA': 'Virginia',\n",
    "        'VT': 'Vermont',\n",
    "        'WA': 'Washington',\n",
    "        'WI': 'Wisconsin',\n",
    "        'WV': 'West Virginia',\n",
    "        'WY': 'Wyoming'\n",
    "}\n",
    "\n",
    "#adapted from  https://github.com/dataiap/dataiap/blob/master/resources/util/map_util.py\n",
    "#load in state geometry\n",
    "state2poly = defaultdict(list)\n",
    "\n",
    "data = json.load(file(\"us-states.json\"))\n",
    "\n",
    "for f in data['features']:\n",
    "    state = states_abbrev[f['abbrev']]\n",
    "    geo = f['geometry']\n",
    "    if geo['type'] == 'Polygon':\n",
    "        for coords in geo['coordinates']:\n",
    "            state2poly[state].append(coords)\n",
    "    elif geo['type'] == 'MultiPolygon':\n",
    "        for polygon in geo['coordinates']:\n",
    "            state2poly[state].extend(polygon)\n",
    "\n",
    "# Look at this link that describes the * and ** for Python arguments\n",
    "# https://docs.python.org/dev/tutorial/controlflow.html#more-on-defining-functions\n",
    "# In brief, * and ** for accepting arbitrary number of arguments. * as tuples and ** as dictionary \n",
    "            \n",
    "def draw_state(plot, stateid, **kwargs):\n",
    "    for polygon in state2poly[stateid]:\n",
    "        xs, ys = zip(*polygon)\n",
    "        plot.fill(xs, ys, **kwargs)\n",
    "\n",
    "\n",
    "def make_map(states, label):\n",
    "    fig = plt.figure(figsize=(12, 9))\n",
    "    ax = plt.gca()\n",
    "\n",
    "    #cmap = cm.binary\n",
    "    #cmap = cm.copper\n",
    "    cmap = cm.Reds\n",
    "    vmin, vmax = 0, states.max().item()//1000\n",
    "    norm = mpl.colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "    \n",
    "    for state in states_abbrev.values():\n",
    "        color = cmap(norm(states.ix[state].item()//1000))\n",
    "        draw_state(ax, state, color = color, ec='k')\n",
    "\n",
    "        \n",
    "    #add an inset colorbar\n",
    "    ax1 = fig.add_axes([0.45, 0.70, 0.4, 0.02])    \n",
    "    mpl.colorbar.ColorbarBase(ax1, cmap=cmap, norm=norm, orientation='horizontal')\n",
    "    ax1.set_title(label)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlim(-180, -60)\n",
    "    ax.set_ylim(15, 75)\n",
    "    return ax\n",
    "\n",
    "rows=db.read(\"select trim(state),count(state) as unique_visitors from logs group by state order by state\")\n",
    "stateDataSeries=createSeries(rows)\n",
    "statesDF=pd.DataFrame(stateDataSeries)\n",
    "make_map(statesDF,\"Unique Visitor Count by State (1,000's)\")\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
